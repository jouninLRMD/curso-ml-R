---
title: "KNN: Bias-Variance trade-off"
author: "Luis Roberto Mercado Diaz"
date: "09/06/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(class)
library(caret)
library(pROC)
```

En este ejercicio, entrenaremos un clasificador KNN para aprender a distinguir imágenes del dígito "8" de otras del dígito "9". Para ello, vamos a usar las proyecciones a 2D que nos daba el análisis de componentes principales.

## Funciones auxiliares

* show_digit: Hace una gráfica del dígito en cuestión.
* load_image_file: Para cargar las imágenes de los dígitos
* load_label_file: Para cargar las etiquetas

```{r, message=F}
show_digit = function(arr784, col = gray(12:1 / 12), ...) {
  image(matrix(as.matrix(arr784[-785]), nrow = 28)[, 28:1], col = col, ...)
}

load_image_file = function(filename) {
  ret = list()
  f = file(filename, 'rb')
  readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  n    = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed = FALSE)
  close(f)
  data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))
}

load_label_file = function(filename) {
  f = file(filename, 'rb')
  readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)
  close(f)
  y
}
```

## Lectura de Datos

Cargamos el dataset MNIST.

```{r, message=F}
df = load_image_file("src/t10k-images.idx3-ubyte")
df$y  = as.factor(load_label_file("src/t10k-labels.idx1-ubyte"))
```

Esta base de datos consta de 10000 imágenes en escala de gris a 28 x 28, de los dígitos del 0 al 9 (escritos a mano).

```{r, message=F}
dim(df)
```

Visualizamos algún ejemplo 

```{r, message=F}
show_digit(df[1, ])
```

Selecciona únicamente las imágens de los dígitos 8  y 9.

```{r}
## Código
```


## Creación de conjuntos de train, test y validación.

Divide los datos en train y test, utilizando porcentajes 70, 30; respectivamente.

```{r, message=F}
## Código
```

## Proyección a 2D usando PCA

Proyecta los datos de entrenamiento a dos dimensiones usando el paquete prcomp. Crea un dataframe para el conjunto de entrenamiento y llámalo train_proy. Convierte la etiqueta a variable de tipo factor y cambia el nombre de los niveles a "n8" y "n9".
```{r, message=F}
## Código
```


Puedes visualizar el conjunto de entrenamiento
```{r}
p = ggplot(train_proy, aes(x = PC1, y=PC2, colour=label) ) + geom_point()
p
```

Proyecta los datos de test y validación a 2D (OJO, usa las matrices de proyección generadas por el PCA del conjunto de train, de otra manera son trampas. Piensa por qué). Crea el conjunto de test, recuerda renombrar los niveles de la etiqueta.

```{r, message=F}
## Código
```

## Entrenamiento

Entrena un clasificador KNN usando el paquete caret. Usar validación cruzada con 5 folds y 3 repeticiones para estimar el número optimo de vecinos. Primero definir los controles del training.

```{r}
## Código
```


Una vez definidos, entrenar el algoritmo

```{r}
## Código
```


Representar el número de vecinos frente al valor de AUC. ¿Cuál es el número óptimo de vecinos?

```{r}
model1$bestTune
```

## AUC en el conjunto de test

Estima el valor de la AUC en el conjunto de test y pinta la curva ROC

```{r}
## Código
```

## Overfitting

Juega con el valor del número de vecinos para entender el comportamiento observado en el gráfico anterior. Utiliza esta función para pintar la frontera de decisión.

```{r}

plot_decision_boundary = function(train_proy, k){
  title = paste0(k, "-nearest neighbour")
  x <- train_proy[, c("PC1", "PC2")]
  g <- train_proy$label
  px1 <- seq(min(train_proy$PC1), max(train_proy$PC1), length.out = 20)
  px2 <- seq(min(train_proy$PC2), max(train_proy$PC2), length.out = 20)
  xnew <- expand.grid(px1, px2)
  mod15 <- knn(x, xnew, g, k=k, prob=TRUE)
  prob <- attr(mod15, "prob")
  prob <- ifelse(mod15=="n8", prob, 1-prob)
  
  prob15 <- matrix(prob, length(px1), length(px2))
  par(mar=rep(2,4))
  contour(px1, px2, prob15, levels=0.7, labels="", xlab="", ylab="", main=
          title, axes=FALSE)
  points(x, col=ifelse(g=="n8", "coral", "cornflowerblue"))
  gd <- expand.grid(x=px1, y=px2)
  points(gd, pch=".", cex=3.0, col=ifelse(prob15>0.5, "coral", "cornflowerblue"))
  box()
}


```

```{r}
## Código
```

     
     
